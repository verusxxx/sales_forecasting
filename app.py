import streamlit as st
import pandas as pd
import tempfile

from src.model import load_model
from src.preprocessing import clean_data, feature_engineering
from src.forecast import forecast
from src.utils import calc_metrics

st.set_page_config(page_title="–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂", layout="wide")
st.title("üìà –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ –Ω–∞ 7 –¥–Ω–µ–π")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª —Å –∏—Å—Ç–æ—Ä–∏–µ–π –ø—Ä–æ–¥–∞–∂", type=["xlsx"])

if uploaded_file:
    st.success("–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ. –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")

    # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
        tmp.write(uploaded_file.read())
        file_path = tmp.name

    df = pd.read_excel(file_path)

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–æ–¥—É
    df = df.rename(columns={
        '–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è_—Ç–æ–≤–∞—Ä–∞',
        '–ì—Ä—É–ø–ø–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤': '–ì—Ä—É–ø–ø–∞_–∫–ª–∏–µ–Ω—Ç–æ–≤',
        '–§–æ—Ä–º–∞—Ç —Ç–æ—á–∫–∏': '–§–æ—Ä–º–∞—Ç_—Ç–æ—á–∫–∏',
        '–ü—Ä–æ–¥–∞–∂–∏, –∫–≥': '–ü—Ä–æ–¥–∞–∂–∏_–∫–≥'
    })

    st.subheader("üîç –ü—Ä–µ–≤—å—é –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    st.dataframe(df.head())

    df = clean_data(df)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±—É–¥—É—â–∏—Ö –¥–∞—Ç
    def make_future_dataframe(df, periods=7):
        last_date = df['–î–∞—Ç–∞'].max()
        unique_combinations = df[['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_—Ç–æ–≤–∞—Ä–∞', '–¢–æ–≤–∞—Ä', '–ì–æ—Ä–æ–¥', '–ì—Ä—É–ø–ø–∞_–∫–ª–∏–µ–Ω—Ç–æ–≤', '–§–æ—Ä–º–∞—Ç_—Ç–æ—á–∫–∏']].drop_duplicates()
        future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=periods)
        future_df = unique_combinations.assign(key=1).merge(
            pd.DataFrame({'–î–∞—Ç–∞': future_dates, 'key': 1}), on='key'
        ).drop('key', axis=1)
        return future_df

    future_df = make_future_dataframe(df, periods=7)
    future_df['–ü—Ä–æ–¥–∞–∂–∏_–∫–≥'] = 0

    full_df = pd.concat([df, future_df], ignore_index=True)
    full_df = feature_engineering(full_df)

    # –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –±—É–¥—É—â–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
    mask_future = full_df['–î–∞—Ç–∞'] > df['–î–∞—Ç–∞'].max()
    features = [col for col in full_df.columns if col not in ['–ü—Ä–æ–¥–∞–∂–∏_–∫–≥', '–î–∞—Ç–∞']]
    X_future = full_df.loc[mask_future, features]

    # –ü—Ä–æ–≥–Ω–æ–∑
    model = load_model()
    preds = forecast(model, X_future)

    result = future_df.copy()
    result['prediction'] = preds

    st.subheader("üìä –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ 7 –¥–Ω–µ–π")
    st.dataframe(result)

    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ
    csv = result.to_csv(index=False).encode('utf-8-sig')
    st.download_button("üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –≤ CSV", data=csv, file_name="sales_forecast_next_7_days.csv")

    # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–∞—Å—Ç–æ—è—â–∏–µ –ø—Ä–æ–¥–∞–∂–∏ ‚Äî —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º
    real = df[df['–î–∞—Ç–∞'].isin(result['–î–∞—Ç–∞'])][
        ['–î–∞—Ç–∞', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è_—Ç–æ–≤–∞—Ä–∞', '–¢–æ–≤–∞—Ä', '–ì–æ—Ä–æ–¥', '–ì—Ä—É–ø–ø–∞_–∫–ª–∏–µ–Ω—Ç–æ–≤', '–§–æ—Ä–º–∞—Ç_—Ç–æ—á–∫–∏', '–ü—Ä–æ–¥–∞–∂–∏_–∫–≥']
    ]
    result = result.merge(real, on=['–î–∞—Ç–∞', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è_—Ç–æ–≤–∞—Ä–∞', '–¢–æ–≤–∞—Ä', '–ì–æ—Ä–æ–¥', '–ì—Ä—É–ø–ø–∞_–∫–ª–∏–µ–Ω—Ç–æ–≤', '–§–æ—Ä–º–∞—Ç_—Ç–æ—á–∫–∏'], how='left')

    if '–ü—Ä–æ–¥–∞–∂–∏_–∫–≥' in result.columns and result['–ü—Ä–æ–¥–∞–∂–∏_–∫–≥'].notna().any():
        y_true = result['–ü—Ä–æ–¥–∞–∂–∏_–∫–≥'].fillna(0)
        y_pred = result['prediction']
        metrics = calc_metrics(y_true, y_pred)

        st.subheader("üìè –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞")
        st.markdown(f"- **MAE**: `{metrics['MAE']:.2f}`")
        st.markdown(f"- **RMSE**: `{metrics['RMSE']:.2f}`")
        mape_str = f"{metrics['MAPE']:.2f}%`" if not pd.isna(metrics['MAPE']) else "‚Äî"
        st.markdown(f"- **MAPE**: `{mape_str}`")
